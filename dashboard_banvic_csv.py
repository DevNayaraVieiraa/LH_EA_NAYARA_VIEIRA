"""
Dashboard Interativo BanVic - Vers√£o CSV
Compat√≠vel com os arquivos do seu reposit√≥rio
"""

import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class BanVicDashboard:
    def __init__(self, data_path=''):
        """
        Inicializa o dashboard com o caminho dos dados
        """
        self.data_path = data_path
        self.load_data()
        self.prepare_data()
        
    def load_data(self):
        """
        Carrega todos os datasets necess√°rios
        """
        print("üìÇ Carregando dados...")
        
        # Tentando carregar os CSVs primeiro (seus arquivos)
        try:
            # Carregando os CSVs do seu reposit√≥rio (com os nomes corretos)
            self.df_agencias = pd.read_csv(f'{self.data_path}agencias.csv')
            self.df_clientes = pd.read_csv(f'{self.data_path}clientes.csv')
            self.df_transacoes = pd.read_csv(f'{self.data_path}transacoes.csv')
            # Voc√™ pode adicionar os outros arquivos aqui se precisar deles
            # self.df_colaboradores = pd.read_csv(f'{self.data_path}colaboradores.csv')
            # self.df_contas = pd.read_csv(f'{self.data_path}contas.csv')
            
            print("‚úÖ Dados CSV carregados com sucesso!")
            
        except FileNotFoundError:
            print("‚ùå Arquivos CSV n√£o encontrados.")
            print(f"üìã Verifique se os arquivos est√£o na pasta: {self.data_path}")
            raise
            
        # Carregando dimens√£o de datas se existir
        try:
            self.dim_dates = pd.read_csv(f'{self.data_path}dim_dates.csv')
        except:
            self.create_dim_dates()
            
    def create_dim_dates(self):
        """
        Cria a dimens√£o de datas caso n√£o exista
        """
        # Convertendo data_transacao para datetime, deixando o pandas detectar o formato
        self.df_transacoes['data_transacao'] = pd.to_datetime(self.df_transacoes['data_transacao'])
        
        # Pegando range de datas das transa√ß√µes
        min_date = self.df_transacoes['data_transacao'].min()
        max_date = self.df_transacoes['data_transacao'].max()
        
        # Criando dimens√£o de datas
        date_range = pd.date_range(start=min_date, end=max_date, freq='D')
        
        self.dim_dates = pd.DataFrame({
            'data': date_range,
            'ano': date_range.year,
            'mes': date_range.month,
            'dia': date_range.day,
            'dia_semana': date_range.dayofweek,
            'nome_dia_semana': date_range.strftime('%A'),
            'nome_mes': date_range.strftime('%B'),
            'trimestre': date_range.quarter,
            'semana_ano': date_range.isocalendar().week,
            'eh_fim_semana': (date_range.dayofweek >= 5).astype(int),
            'mes_par': (date_range.month % 2 == 0).astype(int)
        })
        
    def prepare_data(self):
        """
        Prepara e enriquece os dados para an√°lise
        """
        print("üîß Preparando dados...")
        
        # Merge das tabelas
        self.df_completo = self.df_transacoes.merge(
            self.df_clientes, 
            on='cliente_id', 
            how='left'
        ).merge(
            self.df_agencias, 
            on='agencia_id', 
            how='left'
        )
        
        # Convertendo data para datetime (j√° foi feito, mas garantimos)
        self.df_completo['data_transacao'] = pd.to_datetime(self.df_completo['data_transacao'])
        
        # Adicionando informa√ß√µes de data
        self.df_completo['ano'] = self.df_completo['data_transacao'].dt.year
        self.df_completo['mes'] = self.df_completo['data_transacao'].dt.month
        self.df_completo['dia'] = self.df_completo['data_transacao'].dt.day
        self.df_completo['dia_semana'] = self.df_completo['data_transacao'].dt.day_name()
        self.df_completo['mes_nome'] = self.df_completo['data_transacao'].dt.strftime('%B')
        
        # Calculando √∫ltimos 6 meses
        data_corte = self.df_completo['data_transacao'].max() - pd.DateOffset(months=6)
        self.df_ultimos_6_meses = self.df_completo[
            self.df_completo['data_transacao'] >= data_corte
        ]
        
        print("‚úÖ Dados preparados!")
        print(f"üìä Total de transa√ß√µes: {len(self.df_completo):,}")
        print(f"üë• Total de clientes: {self.df_completo['cliente_id'].nunique():,}")
        print(f"üè¢ Total de ag√™ncias: {self.df_completo['agencia_id'].nunique()}")
        
    def analise_ultimos_6_meses(self):
        """
        An√°lise espec√≠fica dos √∫ltimos 6 meses - Item 5 do desafio
        """
        print("\n" + "="*60)
        print("üìä AN√ÅLISE DOS √öLTIMOS 6 MESES")
        print("="*60)
        
        # Estat√≠sticas por ag√™ncia nos √∫ltimos 6 meses
        stats_6m = self.df_ultimos_6_meses.groupby('nome_agencia').agg({
            'transacao_id': 'count',
            'valor': 'sum'
        }).round(2)
        
        stats_6m.columns = ['total_transacoes', 'volume_total']
        stats_6m = stats_6m.sort_values('total_transacoes', ascending=False)
        
        # Top 3 melhores
        top3 = stats_6m.head(3)
        print("\nüèÜ TOP 3 AG√äNCIAS (√öltimos 6 meses):")
        for i, (agencia, dados) in enumerate(top3.iterrows(), 1):
            print(f"{i}. {agencia}: {dados['total_transacoes']:.0f} transa√ß√µes | R$ {dados['volume_total']:,.2f}")
        
        # Bottom 3 piores
        bottom3 = stats_6m.tail(3)
        print("\nüìâ BOTTOM 3 AG√äNCIAS (√öltimos 6 meses):")
        for i, (agencia, dados) in enumerate(bottom3.iterrows(), len(stats_6m)-2):
            print(f"{i}. {agencia}: {dados['total_transacoes']:.0f} transa√ß√µes | R$ {dados['volume_total']:,.2f}")
        
        # Ag√™ncia com maior n√∫mero de transa√ß√µes
        melhor_agencia = stats_6m.index[0]
        melhor_trans = stats_6m.iloc[0]['total_transacoes']
        
        # Ag√™ncia com menor n√∫mero de transa√ß√µes
        pior_agencia = stats_6m.index[-1]
        pior_trans = stats_6m.iloc[-1]['total_transacoes']
        
        print(f"\n‚úÖ MAIOR n√∫mero de transa√ß√µes: {melhor_agencia} ({melhor_trans:.0f} transa√ß√µes)")
        print(f"‚ùå MENOR n√∫mero de transa√ß√µes: {pior_agencia} ({pior_trans:.0f} transa√ß√µes)")
        
        return stats_6m
        
    def analise_dia_semana(self):
        """
        An√°lise por dia da semana - Item 3 do desafio
        """
        print("\n" + "="*60)
        print("üìÖ AN√ÅLISE POR DIA DA SEMANA")
        print("="*60)
        
        # Filtrando apenas transa√ß√µes aprovadas
        df_aprovadas = self.df_completo[self.df_completo['status'] == 'Aprovada']
        
        # Agrupando por dia da semana
        stats_dia = df_aprovadas.groupby('dia_semana').agg({
            'transacao_id': 'count',
            'valor': ['sum', 'mean']
        }).round(2)
        
        stats_dia.columns = ['qtd_aprovadas', 'volume_total', 'media_valor']
        
        # Reordenando dias
        dias_ordem = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        dias_pt = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
        
        stats_dia = stats_dia.reindex(dias_ordem)
        
        # Encontrando o dia com maior m√©dia
        dia_maior_media = stats_dia['media_valor'].idxmax()
        dia_maior_volume = stats_dia['volume_total'].idxmax()
        
        idx_media = dias_ordem.index(dia_maior_media)
        idx_volume = dias_ordem.index(dia_maior_volume)
        
        print(f"\nüìä Dia com MAIOR M√âDIA de transa√ß√µes aprovadas:")
        print(f"   {dias_pt[idx_media]} - M√©dia: R$ {stats_dia.loc[dia_maior_media, 'media_valor']:,.2f}")
        
        print(f"\nüí∞ Dia com MAIOR VOLUME movimentado:")
        print(f"   {dias_pt[idx_volume]} - Volume: R$ {stats_dia.loc[dia_maior_volume, 'volume_total']:,.2f}")
        
        return stats_dia
        
    def analise_meses_pares_impares(self):
        """
        An√°lise de meses pares vs √≠mpares - Item 3 do desafio
        """
        print("\n" + "="*60)
        print("üìä AN√ÅLISE: MESES PARES VS √çMPARES")
        print("="*60)
        
        # Classificando meses
        self.df_completo['mes_tipo'] = self.df_completo['mes'].apply(
            lambda x: 'Par' if x % 2 == 0 else '√çmpar'
        )
        
        # Estat√≠sticas por tipo de m√™s
        stats_mes = self.df_completo.groupby('mes_tipo').agg({
            'valor': ['mean', 'sum', 'count']
        }).round(2)
        
        stats_mes.columns = ['volume_medio', 'volume_total', 'qtd_transacoes']
        
        # Comparando m√©dias
        media_pares = stats_mes.loc['Par', 'volume_medio']
        media_impares = stats_mes.loc['√çmpar', 'volume_medio']
        
        print(f"\nüìà Volume m√©dio de transa√ß√µes:")
        print(f"   Meses PARES: R$ {media_pares:,.2f}")
        print(f"   Meses √çMPARES: R$ {media_impares:,.2f}")
        
        diferenca_percentual = ((media_pares - media_impares) / media_impares * 100)
        
        if abs(diferenca_percentual) > 10:
            print(f"\n‚ö†Ô∏è DIFEREN√áA SIGNIFICATIVA DETECTADA!")
            print(f"   Meses pares t√™m {diferenca_percentual:+.1f}% de diferen√ßa")
            print(f"   ‚ùå A afirma√ß√£o do analista est√° PARCIALMENTE CORRETA")
        else:
            print(f"\n‚úÖ Diferen√ßa de apenas {diferenca_percentual:+.1f}%")
            print(f"   ‚ùå A afirma√ß√£o do analista est√° INCORRETA")
            print(f"   N√£o h√° diferen√ßa significativa entre meses pares e √≠mpares")
        
        return stats_mes
        
    def export_to_powerbi(self):
        """
        Exporta dados preparados para Power BI
        """
        print("\nüì§ Exportando dados para Power BI...")
        
        # Criando pasta para exports
        if not os.path.exists('powerbi_data'):
            os.makedirs('powerbi_data')
        
        # Exportando datasets
        self.df_completo.to_csv('powerbi_data/dados_completos.csv', index=False, encoding='utf-8-sig')
        self.dim_dates.to_csv('powerbi_data/dim_dates.csv', index=False, encoding='utf-8-sig')
        
        # Criando resumos
        resumo_agencias = self.df_completo.groupby(['agencia_id', 'nome_agencia']).agg({
            'transacao_id': 'count',
            'valor': ['sum', 'mean'],
            'status': lambda x: (x == 'Aprovada').sum()
        }).reset_index()
        resumo_agencias.columns = ['agencia_id', 'nome_agencia', 'total_trans', 
                                  'volume_total', 'ticket_medio', 'trans_aprovadas']
        resumo_agencias.to_csv('powerbi_data/resumo_agencias.csv', index=False, encoding='utf-8-sig')
        
        print("‚úÖ Dados exportados com sucesso!")
        print("üìÅ Arquivos criados em: ./powerbi_data/")
        
    def generate_all_dashboards(self):
        """
        Gera todos os dashboards e salva em HTML
        """
        print("\nüé® Gerando dashboards...")
        
        # Criando pasta
        if not os.path.exists('dashboards'):
            os.makedirs('dashboards')
        
        # 1. Dashboard de Performance das Ag√™ncias
        fig_agencias = self.create_agency_performance()
        fig_agencias.write_html('dashboards/01_agencias.html')
        
        # 2. Dashboard Temporal
        fig_temporal = self.create_time_analysis()
        fig_temporal.write_html('dashboards/02_temporal.html')
        
        # 3. Dashboard Dia da Semana
        fig_weekday = self.create_weekday_analysis()
        fig_weekday.write_html('dashboards/03_dia_semana.html')
        
        print("‚úÖ Dashboards gerados com sucesso!")
        print("üìÅ Arquivos HTML salvos em: ./dashboards/")
        
    def create_agency_performance(self):
        """
        Cria gr√°fico de performance das ag√™ncias
        """
        # An√°lise por ag√™ncia - √∫ltimos 6 meses
        agency_stats = self.df_ultimos_6_meses.groupby('nome_agencia').agg({
            'transacao_id': 'count',
            'valor': ['sum', 'mean']
        }).round(2)
        
        agency_stats.columns = ['total_transacoes', 'volume_total', 'ticket_medio']
        agency_stats = agency_stats.sort_values('total_transacoes', ascending=False)
        
        # Criando visualiza√ß√£o
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'Top Ag√™ncias - N√∫mero de Transa√ß√µes (6 meses)',
                'Top Ag√™ncias - Volume Total (6 meses)',
                'Ranking Completo de Ag√™ncias',
                'Ticket M√©dio por Ag√™ncia'
            )
        )
        
        # Top por transa√ß√µes
        top_trans = agency_stats.head(10)
        fig.add_trace(
            go.Bar(
                x=top_trans.index,
                y=top_trans['total_transacoes'],
                text=top_trans['total_transacoes'].astype(int),
                textposition='auto',
                marker_color='#1f77b4',
                name='Transa√ß√µes'
            ),
            row=1, col=1
        )
        
        # Top por volume
        top_volume = agency_stats.nlargest(10, 'volume_total')
        fig.add_trace(
            go.Bar(
                x=top_volume.index,
                y=top_volume['volume_total'],
                text=[f'R$ {v/1000:.1f}K' for v in top_volume['volume_total']],
                textposition='auto',
                marker_color='#ff7f0e',
                name='Volume'
            ),
            row=1, col=2
        )
        
        # Ranking completo
        fig.add_trace(
            go.Bar(
                x=agency_stats.index,
                y=agency_stats['total_transacoes'],
                marker_color=['green' if i < 3 else 'red' if i >= len(agency_stats)-3 else 'gray' 
                              for i in range(len(agency_stats))],
                name='Ranking'
            ),
            row=2, col=1
        )
        
        # Ticket m√©dio
        fig.add_trace(
            go.Bar(
                x=agency_stats.index,
                y=agency_stats['ticket_medio'],
                text=[f'R$ {v:.2f}' for v in agency_stats['ticket_medio']],
                textposition='auto',
                marker_color='#2ca02c',
                name='Ticket M√©dio'
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            height=800,
            showlegend=False,
            title_text="üè¢ Performance das Ag√™ncias - √öltimos 6 Meses"
        )
        
        fig.update_xaxes(tickangle=45)
        
        return fig
        
    def create_time_analysis(self):
        """
        Cria an√°lise temporal
        """
        daily_stats = self.df_completo.groupby('data_transacao').agg({
            'transacao_id': 'count',
            'valor': 'sum'
        }).reset_index()
        
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=daily_stats['data_transacao'],
                y=daily_stats['valor'],
                mode='lines',
                fill='tozeroy',
                name='Volume Di√°rio'
            )
        )
        
        fig.update_layout(
            title="üìà Evolu√ß√£o Temporal do Volume de Transa√ß√µes",
            xaxis_title="Data",
            yaxis_title="Volume (R$)",
            height=500
        )
        
        return fig
        
    def create_weekday_analysis(self):
        """
        Cria an√°lise por dia da semana
        """
        # Preparando dados
        weekday_stats = self.df_completo.groupby('dia_semana').agg({
            'transacao_id': 'count',
            'valor': 'sum'
        })
        
        # Ordenando
        dias_ordem = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        dias_pt = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
        weekday_stats = weekday_stats.reindex(dias_ordem)
        weekday_stats.index = dias_pt
        
        # Criando gr√°fico
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('Transa√ß√µes por Dia da Semana', 'Volume por Dia da Semana')
        )
        
        fig.add_trace(
            go.Bar(
                x=weekday_stats.index,
                y=weekday_stats['transacao_id'],
                marker_color=['#1f77b4' if i < 5 else '#ff7f0e' for i in range(7)],
                text=weekday_stats['transacao_id'],
                textposition='auto'
            ),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Bar(
                x=weekday_stats.index,
                y=weekday_stats['valor'],
                marker_color=['#2ca02c' if i < 5 else '#d62728' for i in range(7)],
                text=[f'R$ {v/1000:.1f}K' for v in weekday_stats['valor']],
                textposition='auto'
            ),
            row=1, col=2
        )
        
        fig.update_layout(
            height=400,
            showlegend=False,
            title_text="üìÖ An√°lise por Dia da Semana"
        )
        
        return fig

def main():
    """
    Fun√ß√£o principal
    """
    print("\n" + "="*60)
    print("üè¶ DASHBOARD BANVIC - AN√ÅLISE DE DADOS")
    print("="*60 + "\n")
    
    try:
        # ############################################################### #
        # ## CORRE√á√ÉO PRINCIPAL: Informar o caminho correto dos dados ### #
        # ############################################################### #
        dashboard = BanVicDashboard(data_path='dados/raw/banvic_data/')
        
        # Executando an√°lises espec√≠ficas do desafio
        dashboard.analise_ultimos_6_meses()
        dashboard.analise_dia_semana()
        dashboard.analise_meses_pares_impares()
        
        # Gerando dashboards
        dashboard.generate_all_dashboards()
        
        # Exportando para Power BI
        dashboard.export_to_powerbi()
        
        print("\n" + "="*60)
        print("üéâ PROCESSO CONCLU√çDO COM SUCESSO!")
        print("="*60)
        print("\nüìä Arquivos gerados:")
        print("   ‚úÖ Dashboards HTML em: ./dashboards/")
        print("   ‚úÖ Dados para Power BI em: ./powerbi_data/")
        print("\nüí° Pr√≥ximos passos:")
        print("   1. Abra os arquivos HTML para visualizar os dashboards")
        print("   2. Importe os CSVs no Power BI Desktop")
        print("   3. Use as an√°lises geradas para seu relat√≥rio")
        
    except FileNotFoundError as e:
        print("\n‚ùå ERRO: Arquivos de dados n√£o encontrados!")
        print(f"\nüìã Verifique se a pasta e os arquivos existem no caminho especificado.")
        print("\nüí° Dica: Confira se os nomes dos arquivos CSV est√£o corretos (ex: agencias.csv)")

if __name__ == "__main__":
    main()