# Script de ETL para o desafio BanVic - PreparaÃ§Ã£o dos dados para o Power BI
# Autor: Nayara Vieira
# Data: 07/09/2025

import pandas as pd
import numpy as np
from pathlib import Path
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def safe_date_conversion(date_series, column_name="data"):
    """
    Converte uma coluna de data para o formato datetime, tentando vÃ¡rios formatos.
    """
    print(f"  ğŸ”„ Processando {column_name}...")
    
    # Tenta converter a data de forma automÃ¡tica, que Ã© mais rÃ¡pido
    try:
        converted = pd.to_datetime(date_series, infer_datetime_format=True, errors='coerce')
        valid_count = converted.notna().sum()
        print(f"  âœ… {column_name}: {valid_count}/{len(date_series)} datas convertidas com sucesso")
        return converted
    except Exception as e:
        print(f"  âš ï¸ Erro na conversÃ£o automÃ¡tica de {column_name}: {e}")
        
        # Se a conversÃ£o automÃ¡tica falhar, tenta na mÃ£o com os formatos mais comuns
        formats_to_try = [
            '%Y-%m-%d %H:%M:%S UTC',
            '%Y-%m-%d %H:%M:%S.%f UTC', 
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d',
            'mixed'
        ]
        
        for fmt in formats_to_try:
            try:
                if fmt == 'mixed':
                    converted = pd.to_datetime(date_series, format='mixed', errors='coerce')
                else:
                    converted = pd.to_datetime(date_series, format=fmt, errors='coerce')
                
                valid_count = converted.notna().sum()
                if valid_count > 0:
                    print(f"  âœ… {column_name}: {valid_count}/{len(date_series)} datas convertidas (formato: {fmt})")
                    return converted
            except Exception:
                continue
        
        print(f"  âŒ NÃ£o foi possÃ­vel converter {column_name}. Mantendo como string.")
        return date_series

def load_banvic_data():
    """
    FunÃ§Ã£o principal que carrega, limpa, junta e salva os dados do BanVic.
    """
    # Definindo os caminhos das pastas pra organizar o projeto
    base_path = Path(r"C:\Users\Nayara\Desktop\LH_EA_NAYARA_VIEIRA")
    data_path = base_path / "dados" / "raw" / "banvic_data"
    processed_path = base_path / "dados" / "processed"
    
    # Garante que a pasta de destino exista
    processed_path.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ¦ Carregando dados do BanVic para Power BI...")
    print("="*60)
    
    # 1. Leitura dos arquivos CSV originais
    try:
        # Tabela Fato: transacoes.csv
        df_transacoes = pd.read_csv(data_path / "transacoes.csv")
        print(f"âœ… TransaÃ§Ãµes carregadas: {len(df_transacoes):,} registros")
        
        # DimensÃµes
        df_clientes = pd.read_csv(data_path / "clientes.csv")
        print(f"âœ… Clientes carregados: {len(df_clientes):,} registros")
        
        df_agencias = pd.read_csv(data_path / "agencias.csv")
        print(f"âœ… AgÃªncias carregadas: {len(df_agencias):,} registros")
        
        df_contas = pd.read_csv(data_path / "contas.csv")
        print(f"âœ… Contas carregadas: {len(df_contas):,} registros")
        
    except FileNotFoundError as e:
        print(f"âŒ Erro: Arquivo nÃ£o encontrado - {e}")
        return None
    except Exception as e:
        print(f"âŒ Erro ao carregar dados: {e}")
        return None
    
    print("\nğŸ“… PROCESSAMENTO DE DATAS")
    print("="*40)
    
    # 2. Tratamento da coluna de data_transacao
    df_transacoes['data_transacao'] = safe_date_conversion(
        df_transacoes['data_transacao'], 
        "data_transacao"
    )
    
    # O Power BI pode se confundir com timezone, melhor remover
    if pd.api.types.is_datetime64_any_dtype(df_transacoes['data_transacao']):
        if df_transacoes['data_transacao'].dt.tz is not None:
            df_transacoes['data_transacao'] = df_transacoes['data_transacao'].dt.tz_localize(None)
    
    # Checa se a data foi convertida antes de criar novas colunas
    if pd.api.types.is_datetime64_any_dtype(df_transacoes['data_transacao']):
        print("  ğŸ”§ Criando colunas derivadas de data...")
        
        # Quebrando a data em vÃ¡rias colunas para facilitar os filtros no PBI
        df_transacoes['ano'] = df_transacoes['data_transacao'].dt.year
        df_transacoes['mes'] = df_transacoes['data_transacao'].dt.month
        df_transacoes['dia'] = df_transacoes['data_transacao'].dt.day
        df_transacoes['dia_semana'] = df_transacoes['data_transacao'].dt.day_name()
        df_transacoes['mes_nome'] = df_transacoes['data_transacao'].dt.month_name()
        df_transacoes['trimestre'] = df_transacoes['data_transacao'].dt.quarter
        df_transacoes['semana_ano'] = df_transacoes['data_transacao'].dt.isocalendar().week
        
        # Traduzindo para portuguÃªs pra ficar mais fÃ¡cil de ler no relatÃ³rio
        dias_pt = {
            'Monday': 'Segunda-feira', 'Tuesday': 'TerÃ§a-feira', 
            'Wednesday': 'Quarta-feira', 'Thursday': 'Quinta-feira',
            'Friday': 'Sexta-feira', 'Saturday': 'SÃ¡bado', 'Sunday': 'Domingo'
        }
        df_transacoes['dia_semana_pt'] = df_transacoes['dia_semana'].map(dias_pt).fillna(df_transacoes['dia_semana'])
        
        meses_pt = {
            'January': 'Janeiro', 'February': 'Fevereiro', 'March': 'MarÃ§o',
            'April': 'Abril', 'May': 'Maio', 'June': 'Junho',
            'July': 'Julho', 'August': 'Agosto', 'September': 'Setembro',
            'October': 'Outubro', 'November': 'Novembro', 'December': 'Dezembro'
        }
        df_transacoes['mes_nome_pt'] = df_transacoes['mes_nome'].map(meses_pt).fillna(df_transacoes['mes_nome'])
        
        # Coluna para a anÃ¡lise de meses pares vs. Ã­mpares
        df_transacoes['mes_tipo'] = df_transacoes['mes'].apply(
            lambda x: 'Par' if pd.notna(x) and x % 2 == 0 else 'Ãmpar'
        )
        
    else:
        print("  âš ï¸ Datas nÃ£o foram convertidas. Pulando criaÃ§Ã£o de colunas derivadas.")
    
    print("\nğŸ”— FAZENDO JOINS DOS DADOS")
    print("="*40)
    
    # 3. Juntando tudo em uma tabela sÃ³ (modelo desnormalizado para o CSV final)
    try:
        # TransaÃ§Ãµes <- Contas (para pegar cod_agencia e cod_cliente)
        df_transacoes_completo = df_transacoes.merge(
            df_contas[['num_conta', 'cod_agencia', 'cod_cliente']], 
            on='num_conta', 
            how='left'
        )
        print(f"âœ… Join transaÃ§Ãµes + contas: {len(df_transacoes_completo):,} registros")
        
        # Join com a tabela de clientes
        colunas_clientes = [col for col in ['cod_cliente', 'primeiro_nome', 'ultimo_nome', 'tipo_cliente', 'endereco'] 
                            if col in df_clientes.columns]
        
        df_transacoes_completo = df_transacoes_completo.merge(
            df_clientes[colunas_clientes], 
            on='cod_cliente', 
            how='left'
        )
        print(f"âœ… Join + clientes: {len(df_transacoes_completo):,} registros")
        
        # Join com a tabela de agÃªncias
        colunas_agencias = [col for col in ['cod_agencia', 'nome', 'cidade', 'uf', 'tipo_agencia'] 
                            if col in df_agencias.columns]
        
        df_transacoes_completo = df_transacoes_completo.merge(
            df_agencias[colunas_agencias], 
            on='cod_agencia', 
            how='left',
            suffixes=('', '_agencia')
        )
        print(f"âœ… Join + agÃªncias: {len(df_transacoes_completo):,} registros")
        
        # Renomeando colunas para evitar conflitos de nome e melhorar a clareza
        if 'nome' in df_transacoes_completo.columns:
            df_transacoes_completo = df_transacoes_completo.rename(columns={'nome': 'nome_agencia'})
        if 'endereco' in df_transacoes_completo.columns:
            df_transacoes_completo = df_transacoes_completo.rename(columns={'endereco': 'endereco_cliente'})
            
    except Exception as e:
        print(f"âš ï¸ Erro no join: {e}")
        df_transacoes_completo = df_transacoes.copy()
    
    print("\nğŸ“Š CRIANDO MÃ‰TRICAS CALCULADAS")
    print("="*40)
    
    # 4. Criando algumas colunas calculadas direto no script
    try:
        # Criando faixas de valor pra facilitar a anÃ¡lise
        if 'valor_transacao' in df_transacoes_completo.columns:
            df_transacoes_completo['categoria_valor'] = pd.cut(
                df_transacoes_completo['valor_transacao'],
                bins=[0, 100, 500, 1000, 5000, float('inf')],
                labels=['AtÃ© R$ 100', 'R$ 101-500', 'R$ 501-1000', 'R$ 1001-5000', 'Acima de R$ 5000'],
                include_lowest=True
            )
            print("âœ… Categoria de valor criada")
            
    except Exception as e:
        print(f"âš ï¸ Erro ao criar mÃ©tricas: {e}")
    
    print("\nğŸ“… CRIANDO DIMENSÃƒO DE DATAS")
    print("="*40)
    
    # 5. Criando a dim_datas separada (melhor prÃ¡tica de BI)
    if pd.api.types.is_datetime64_any_dtype(df_transacoes_completo['data_transacao']):
        try:
            # Pega a data mÃ­nima e mÃ¡xima das transaÃ§Ãµes pra criar o range
            data_min = df_transacoes_completo['data_transacao'].min()
            data_max = df_transacoes_completo['data_transacao'].max()
            
            print(f"  ğŸ“… PerÃ­odo: {data_min.date()} a {data_max.date()}")
            
            # Cria um range de todas as datas no perÃ­odo, sem faltar nenhuma
            datas_completas = pd.date_range(start=data_min.date(), end=data_max.date(), freq='D')
            
            # Monta o DataFrame da dimensÃ£o de datas
            dim_dates = pd.DataFrame({
                'data': datas_completas,
                'ano': datas_completas.year,
                'mes': datas_completas.month,
                'dia': datas_completas.day,
                'dia_semana': datas_completas.day_name(),
                'mes_nome': datas_completas.month_name(),
                'trimestre': datas_completas.quarter,
                'semana_ano': datas_completas.isocalendar().week,
                'dia_ano': datas_completas.dayofyear,
                'semestre': ((datas_completas.quarter + 1) // 2).astype(int)
            })
            
            # Traduz as colunas de data para portuguÃªs
            dim_dates['dia_semana_pt'] = dim_dates['dia_semana'].map(dias_pt)
            dim_dates['mes_nome_pt'] = dim_dates['mes_nome'].map(meses_pt)
            dim_dates['mes_tipo'] = dim_dates['mes'].apply(lambda x: 'Par' if x % 2 == 0 else 'Ãmpar')
            
            print(f"âœ… DimensÃ£o de datas criada: {len(dim_dates):,} registros")
            
        except Exception as e:
            print(f"âš ï¸ Erro ao criar dimensÃ£o de datas: {e}")
            dim_dates = pd.DataFrame()
    else:
        print("âš ï¸ NÃ£o foi possÃ­vel criar dimensÃ£o de datas (data_transacao nÃ£o Ã© datetime)")
        dim_dates = pd.DataFrame()
    
    print("\nğŸ’¾ SALVANDO ARQUIVOS PARA POWER BI")
    print("="*40)
    
    # 6. Exportando os arquivos CSV que serÃ£o usados no Power BI
    try:
        # Tabela principal com tudo junto
        output_file = processed_path / "transacoes_powerbi.csv"
        df_transacoes_completo.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ… {output_file.name}: {len(df_transacoes_completo):,} registros")
        
        # DimensÃµes separadas para montar o modelo estrela no PBI
        df_clientes.to_csv(processed_path / "dim_clientes.csv", index=False, encoding='utf-8-sig')
        print(f"âœ… dim_clientes.csv: {len(df_clientes):,} registros")
        
        df_agencias.to_csv(processed_path / "dim_agencias.csv", index=False, encoding='utf-8-sig')
        print(f"âœ… dim_agencias.csv: {len(df_agencias):,} registros")
        
        if not dim_dates.empty:
            dim_dates.to_csv(processed_path / "dim_datas.csv", index=False, encoding='utf-8-sig')
            print(f"âœ… dim_datas.csv: {len(dim_dates):,} registros")
        
    except Exception as e:
        print(f"âŒ Erro ao salvar arquivos: {e}")
        return None
    
    print("\nğŸ“ˆ CRIANDO RESUMOS EXECUTIVOS")
    print("="*40)
    
    # 7. Gerando alguns resumos prÃ©-calculados (opcional, mas pode ser Ãºtil para validar)
    try:
        if 'dia_semana_pt' in df_transacoes_completo.columns and 'valor_transacao' in df_transacoes_completo.columns:
            # Resumo por dia da semana
            resumo_dias = df_transacoes_completo.groupby('dia_semana_pt').agg({
                'cod_transacao': 'count',
                'valor_transacao': ['sum', 'mean']
            }).round(2)
            resumo_dias.columns = ['Qtd_Transacoes', 'Volume_Total', 'Valor_Medio']
            resumo_dias.to_csv(processed_path / "resumo_dias_semana.csv", encoding='utf-8-sig')
            print("âœ… resumo_dias_semana.csv")
        
        if 'mes_tipo' in df_transacoes_completo.columns:
            # Resumo por mÃªs (par/Ã­mpar)
            resumo_meses = df_transacoes_completo.groupby('mes_tipo').agg({
                'cod_transacao': 'count',
                'valor_transacao': ['sum', 'mean']
            }).round(2)
            resumo_meses.columns = ['Qtd_Transacoes', 'Volume_Total', 'Valor_Medio']
            resumo_meses.to_csv(processed_path / "resumo_meses_tipo.csv", encoding='utf-8-sig')
            print("âœ… resumo_meses_tipo.csv")
        
        # Resumo por agÃªncia (Ãºltimos 6 meses)
        if pd.api.types.is_datetime64_any_dtype(df_transacoes_completo['data_transacao']):
            data_max = df_transacoes_completo['data_transacao'].max()
            data_corte = data_max - pd.DateOffset(months=6)
            dados_recentes = df_transacoes_completo[df_transacoes_completo['data_transacao'] >= data_corte]
            
            if 'cod_agencia' in dados_recentes.columns and len(dados_recentes) > 0:
                agencia_cols = ['cod_agencia']
                if 'nome_agencia' in dados_recentes.columns:
                    agencia_cols.append('nome_agencia')
                
                resumo_agencias = dados_recentes.groupby(agencia_cols).agg({
                    'cod_transacao': 'count',
                    'valor_transacao': ['sum', 'mean']
                }).round(2)
                resumo_agencias.columns = ['Qtd_Transacoes', 'Volume_Total', 'Valor_Medio']
                resumo_agencias = resumo_agencias.sort_values('Qtd_Transacoes', ascending=False)
                resumo_agencias.to_csv(processed_path / "resumo_agencias_6m.csv", encoding='utf-8-sig')
                print("âœ… resumo_agencias_6m.csv")
                
    except Exception as e:
        print(f"âš ï¸ Erro ao criar resumos: {e}")
    
    print("\n" + "="*60)
    print("âœ… PROCESSAMENTO CONCLUÃDO!")
    print("="*60)
    
    # Algumas estatÃ­sticas pra conferir no final
    if pd.api.types.is_datetime64_any_dtype(df_transacoes_completo['data_transacao']):
        data_min = df_transacoes_completo['data_transacao'].min()
        data_max = df_transacoes_completo['data_transacao'].max()
        print(f"ğŸ“Š PerÃ­odo dos dados: {data_min.strftime('%d/%m/%Y')} a {data_max.strftime('%d/%m/%Y')}")
    
    print(f"ğŸ’³ Total de transaÃ§Ãµes: {len(df_transacoes_completo):,}")
    
    if 'valor_transacao' in df_transacoes_completo.columns:
        volume_total = df_transacoes_completo['valor_transacao'].sum()
        print(f"ğŸ’° Volume total: R$ {volume_total:,.2f}")
    
    print(f"ğŸ‘¥ Total de clientes: {len(df_clientes):,}")
    print(f"ğŸ¢ Total de agÃªncias: {len(df_agencias):,}")
    
    print(f"\nğŸ“ Arquivos criados em: {processed_path}")
    print("  - transacoes_powerbi.csv (arquivo principal)")
    print("  - dim_clientes.csv")
    print("  - dim_agencias.csv") 
    if not dim_dates.empty:
        print("  - dim_datas.csv")
    print("  - resumo_dias_semana.csv")
    print("  - resumo_meses_tipo.csv")
    print("  - resumo_agencias_6m.csv")
    print("="*60)
    
    return df_transacoes_completo

# Bloco principal para rodar o script todo
if __name__ == "__main__":
    print("ğŸš€ INICIANDO INTEGRAÃ‡ÃƒO BANVIC + POWER BI")
    print("="*60)
    
    try:
        dados = load_banvic_data()
        if dados is not None:
            print("\nğŸ‰ SUCESSO! Dados prontos para importaÃ§Ã£o no Power BI")
        else:
            print("\nâŒ FALHA no processamento dos dados")
    except Exception as e:
        print(f"\nâŒ ERRO GERAL: {e}")
        import traceback
        traceback.print_exc()